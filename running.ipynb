{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cameron/miniconda3/envs/cam_env_2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "/home/cameron/miniconda3/envs/cam_env_2/lib/python3.11/site-packages/torch/_utils.py:830: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from src.transformers.models.bert import BertModel\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNA_bert_6\", trust_remote_code=True)\n",
    "model = BertModel.from_pretrained(\"zhihan1996/DNA_bert_6\", trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 12\n",
    "num_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_dict = {\"tokens\": list()}\n",
    "vocab_reverse = dict((value, key) for key, value in tokenizer.vocab.items())\n",
    "\n",
    "\n",
    "attention_dict = dict()\n",
    "point_position_dict = dict()\n",
    "agg_attn_dict = dict()\n",
    "for layer in range(num_layers):\n",
    "    attention_dict[layer] = dict()\n",
    "    point_position_dict[layer] = dict()\n",
    "    for head in range(num_heads):\n",
    "        agg_attn_dict[f\"{layer}_{head}\"] = list()\n",
    "        attention_dict[layer][head] = dict()\n",
    "        attention_dict[layer][head][\"layer\"] = layer \n",
    "        attention_dict[layer][head][\"head\"] = head\n",
    "        attention_dict[layer][head][\"tokens\"] = list() \n",
    "        point_position_dict[layer][head] = dict()\n",
    "        point_position_dict[layer][head][\"layer\"] = layer \n",
    "        point_position_dict[layer][head][\"head\"] = head\n",
    "        point_position_dict[layer][head][\"tokens\"] = list()\n",
    "        point_position_dict[layer][head][\"query\"] = list()  \n",
    "        point_position_dict[layer][head][\"key\"] = list()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_1 = \"GGGGTAATCAGAGCAGAACCAGGCACCTGCCCTGCCTGATGTCCTCTGCTCAGGGCTGGCAGCTGTGTCCTGTGTCCTCCCCACCCCCTGGGACCACAAAGCTCCACCCCTGCCACACCCTGACATACTCAAGCCCAGGAGCCTGACCCAGGGCTCAGGGTGGGGTCAAAAACCGGGGGGATCTGATTTGCATGGATGGACTCTCCCCCTCTCAGAGTATGAAGAGAGGGAGAGATCTGGGGGAAGCTCAGCTTCAGCTGTGGTAGAGAAGACAGGATTCAGGACAATCTCCAGCATGGC\"\n",
    "dna_2 = \"AAAGAGACCCGGGGAGCATCTGGGCTTCCAAGGTCCTCGGTACGGCCCAAGGCAGCGAAGGACGCGCGGCTCCAGGCTGCGGGAGCCAGGACGACCGGGGGCTCCCAGAGCGCGAAGTCGCGATCCTCGGCGGTGGAGAGCTCGTGCCAAAACGTCCTCCCCTGCGCCAGTCAGGCCTTCGCGGGGCTGGCAGGCGGGCGGGGGCGGGGCCGCCGCACTTTAAGAGGCTGTGCAGGCAGACAGACCTCCAGGCCCGCTAGGGGATCCGCGCCATGGAGGCCGCCCGGGACTATGCAGGAG\"\n",
    "dna_3 = \"AGACCCCGGAGCCACAAGGAGAGGGCTGGATCCCCGGCTCAGAGGGAAGAGGTCGGATCCCCAGCTGAGAGGGAGGAGGGTCCCGGACCCTAGGAGTGGGAAGGAAAGGCTCGGATCCCCTGATCCCCAGGAGGAGGGGACCCGGCTGCCTCCCGGTTGGGGCCGCGCGAGGGCGGGGCGCGGAAGGATCCGGGAGGGCCGTGCTCCGCCACCCAGTATATATCTGTCCCCAGTCCCCGGGGCCGCCTCATTCCCTGTCCTCGGATCACAGTCTCTTCTCACTACAGTGTCGCCGCCTCT\"\n",
    "dna_4 = \"GTCTTTCCTTGGAGGAGGCATTGGCACGAGTTACTATAAACTCCCTCTGAATCTCAAGACTTCTGGGACGCCGATTCCGCTCCTGGCCTGGGGCAAGGCGTGGGAGCTTGGAAGCCAGCGCTGCGCTCCCCGTGGGAAGCGATCGTCTCCTCTGTCAACTCGCGCCTGGGCACTTAGCCCCTCCCGTTTCAGGGCGCCGCCTCCCCGGATGGCAAACACTATAAAGTGGCGGCGAATAAGGTTCCTCCTGCTGCTCTCGGTTTAGTCCAAGATCAGCGATATCACGCGTCCCCCGGAGCA\"\n",
    "\n",
    "dataset = [dna_1, dna_2, dna_3, dna_4]\n",
    "\n",
    "sentence_stops = list()\n",
    "sentence_starts = list()\n",
    "pos = 0\n",
    "for sequence in dataset:\n",
    "    sentence_starts.append(pos)\n",
    "    inputs = tokenizer(\" \".join([sequence[i:i+6] for i in range(0, len(sequence)-6, 1)]), return_tensors = 'pt')\n",
    "    out = model(**inputs.to(device), output_attentions=True, return_dict=True)\n",
    "    tokens = [vocab_reverse[x] for x in inputs['input_ids'].tolist()[0]]   \n",
    "    pos = pos+len(tokens)\n",
    "    sentence_stops.append(pos) \n",
    "    for i,value in enumerate(tokens):\n",
    "        single_token = {}\n",
    "        single_token['value'] = value\n",
    "        single_token['type'] = \"query\"\n",
    "        single_token[\"length\"] = len(tokens)\n",
    "        single_token['pos_int'] = i\n",
    "        single_token['position'] = i/(len(tokens)- 1)\n",
    "        single_token['sentence'] = \" \".join(tokens) \n",
    "   \n",
    "        tokens_dict['tokens'].append(single_token)\n",
    "        for layer in range(num_layers): \n",
    "            for head in range(num_heads):\n",
    "                point_position_dict[layer][head]['query'].append(out.query[layer][head][i].detach().cpu().numpy())\n",
    "                point_position_dict[layer][head]['key'].append(out.key[layer][head][i].detach().cpu().numpy())\n",
    "                attention_dict[layer][head]['tokens'].append({'attention' : out.attentions[layer][0][head][i].detach().cpu().numpy()})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:39<00:00,  8.29s/it]\n",
      "100%|██████████| 12/12 [01:42<00:00,  8.53s/it]\n",
      "100%|██████████| 12/12 [01:41<00:00,  8.48s/it]\n",
      "100%|██████████| 12/12 [01:41<00:00,  8.44s/it]\n",
      "100%|██████████| 12/12 [01:43<00:00,  8.63s/it]\n",
      "100%|██████████| 12/12 [01:37<00:00,  8.11s/it]\n",
      "100%|██████████| 12/12 [01:35<00:00,  7.96s/it]\n",
      "100%|██████████| 12/12 [01:34<00:00,  7.86s/it]\n",
      "100%|██████████| 12/12 [01:34<00:00,  7.87s/it]\n",
      "100%|██████████| 12/12 [01:35<00:00,  7.99s/it]\n",
      "100%|██████████| 12/12 [01:38<00:00,  8.21s/it]\n",
      "100%|██████████| 12/12 [01:41<00:00,  8.48s/it]\n",
      "100%|██████████| 12/12 [19:46<00:00, 98.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# Getting point positions\n",
    "\n",
    "#Some code from chatGPT!!!!!!!\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "def get_pca_embeddings(vectors, n_components=2):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(vectors)\n",
    "def get_tsne_embeddings(vectors, n_components=2, perplexity=30.0):\n",
    "    tsne = TSNE(n_components=n_components, perplexity=perplexity, n_iter=250)\n",
    "    return tsne.fit_transform(vectors)\n",
    "def get_umap_embeddings(vectors, n_components=2, n_neighbors=15, min_dist=0.1):\n",
    "    umap_model = umap.UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist)\n",
    "    return umap_model.fit_transform(vectors)\n",
    "def calculate_centroid(vectors):\n",
    "    \"\"\"Calculate the centroid of a list of vectors.\"\"\"\n",
    "    return np.mean(vectors, axis=0)\n",
    "def translate_vectors(source_vectors, target_vectors):\n",
    "    \"\"\"Translate source_vectors so their centroid matches that of target_vectors.\"\"\"\n",
    "    source_centroid = calculate_centroid(source_vectors)\n",
    "    target_centroid = calculate_centroid(target_vectors)\n",
    "    translation = target_centroid - source_centroid\n",
    "    translated_vectors = source_vectors + translation\n",
    "    return translated_vectors\n",
    "\n",
    "def calculate_norm(vector):\n",
    "    return np.linalg.norm(vector)\n",
    "\n",
    "for layer in tqdm.tqdm(range(num_layers)): \n",
    "    for head in tqdm.tqdm(range(num_heads)):\n",
    "        translated_key = translate_vectors(point_position_dict[layer][head]['key'], point_position_dict[layer][head]['query'])\n",
    "        vectors = np.stack(point_position_dict[layer][head]['query'] + [np.array(row) for row in translated_key])\n",
    "        \n",
    "        pca_2d = get_pca_embeddings(vectors, n_components=2)\n",
    "        pca_3d = get_pca_embeddings(vectors, n_components=3)\n",
    "\n",
    "        tsne_2d = get_tsne_embeddings(vectors, n_components=2)\n",
    "        tsne_3d = get_tsne_embeddings(vectors, n_components=3)\n",
    "\n",
    "        umap_2d = get_umap_embeddings(vectors, n_components=2)\n",
    "        umap_3d = get_umap_embeddings(vectors, n_components=3)\n",
    "        \n",
    "        for token in range(umap_2d.shape[0]):\n",
    "            point_position_dict[layer][head]['tokens'].append({\n",
    "                \"tsne_x\" : tsne_2d[token][0],\n",
    "                \"tsne_y\" : tsne_2d[token][1],\n",
    "                \n",
    "                \"tsne_x_3d\" : tsne_3d[token][0],\n",
    "                \"tsne_y_3d\" : tsne_3d[token][1],                \n",
    "                \"tsne_z_3d\" : tsne_3d[token][2],                \n",
    "                \n",
    "                \"umap_x\" : umap_2d[token][0],\n",
    "                \"umap_y\" : umap_2d[token][1],          \n",
    "\n",
    "                \"umap_x_3d\" : umap_3d[token][0],\n",
    "                \"umap_y_3d\" : umap_3d[token][1],                \n",
    "                \"umap_z_3d\" : umap_3d[token][2],                         \n",
    "                \n",
    "                \"pca_x\" : pca_2d[token][0],\n",
    "                \"pca_y\" : pca_2d[token][1],\n",
    "                \n",
    "                \"pca_x_3d\" : pca_3d[token][0],\n",
    "                \"pca_y_3d\" : pca_3d[token][1],                                    \n",
    "                \"pca_z_3d\" : pca_3d[token][2],    \n",
    "                \n",
    "                \"norm\" : calculate_norm(vectors[token])                              \n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 260.69it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 174.76it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 146.11it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 173.26it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 174.34it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 157.38it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 163.82it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 191.62it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 170.55it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 171.89it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 157.59it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 158.60it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 13.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for layer in tqdm.tqdm(range(num_layers)): \n",
    "    for head in tqdm.tqdm(range(num_heads)):\n",
    "        avg =  np.average(np.stack([np.stack([token['attention'] for token in attention_dict[layer][head]['tokens'][sentence_starts[i]:sentence_stops[i]]]) for i in range(len(dataset))]),axis=0)\n",
    "        agg_attn_dict[f\"{layer}_{head}\"] = [{\"attention\" : avg[i].tolist()} for i in range(avg.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 539.48it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 629.93it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 609.91it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 623.66it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 604.93it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 442.57it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 662.04it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 530.47it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 423.45it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 425.98it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 544.43it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 611.00it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 32.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for layer in tqdm.tqdm(range(num_layers)): \n",
    "    for head in tqdm.tqdm(range(num_heads)):\n",
    "        del point_position_dict[layer][head][\"query\"]\n",
    "        del point_position_dict[layer][head][\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 131.74it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 126.65it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 125.97it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 130.81it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 135.13it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 138.67it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 146.87it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 138.59it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 149.73it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 148.83it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 143.30it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 141.16it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00, 11.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for layer in tqdm.tqdm(range(num_layers)): \n",
    "    for head in tqdm.tqdm(range(num_heads)):\n",
    "        for i in range(len(point_position_dict[layer][head]['tokens'])):\n",
    "            for data_feature in [\"tsne_x\", \"tsne_y\", \"umap_x\", \"umap_y\", \"norm\", \"tsne_x_3d\", \"tsne_y_3d\", \"tsne_z_3d\", \"umap_x_3d\", \"umap_y_3d\", \"umap_z_3d\", \"pca_x\", \"pca_y\", \"pca_x_3d\", \"pca_y_3d\", \"pca_z_3d\"]:\n",
    "                point_position_dict[layer][head]['tokens'][i][data_feature] = float(point_position_dict[layer][head]['tokens'][i][data_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1184/1184 [00:00<00:00, 4414271.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "tokens = copy.deepcopy(tokens_dict[\"tokens\"])\n",
    "pls = list()\n",
    "for token in tqdm.tqdm(tokens):\n",
    "    token[\"type\"] = \"key\"\n",
    "    tokens_dict[\"tokens\"].append(token)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 57.77it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 55.87it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 88.04it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 135.33it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 142.98it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 144.19it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 150.71it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 145.44it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 148.05it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 152.99it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 150.12it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 163.29it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for layer in tqdm.tqdm(range(num_layers)): \n",
    "    for head in tqdm.tqdm(range(num_heads)):\n",
    "        for att in attention_dict[layer][head]['tokens']:\n",
    "            att['attention'] = att['attention'].tolist() \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/cameron/repos/attention-viz-bio/web/data/DNABERT/agg_attn.json\", \"w\") as fp:\n",
    "    json.dump(agg_attn_dict , fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/cameron/repos/attention-viz-bio/web/data/DNABERT/tokens.json\", \"w\") as fp:\n",
    "    json.dump(tokens_dict , fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.94it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.96it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.92it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.93it/s]\n",
      "100%|██████████| 12/12 [00:02<00:00,  4.33it/s]\n",
      "100%|██████████| 12/12 [00:02<00:00,  4.37it/s]\n",
      "100%|██████████| 12/12 [00:02<00:00,  4.29it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.62it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.13it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.78it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.84it/s]\n",
      "100%|██████████| 12/12 [00:02<00:00,  4.01it/s]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.08s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for layer in tqdm.tqdm(range(num_layers)): \n",
    "    for head in tqdm.tqdm(range(num_heads)):\n",
    "        with open(f\"/home/cameron/repos/attention-viz-bio/web/data/DNABERT/attention/layer{layer}_head{head}.json\", \"w\") as fp:\n",
    "            json.dump(attention_dict[layer][head] , fp) \n",
    "        with open(f\"/home/cameron/repos/attention-viz-bio/web/data/DNABERT/byLayerHead/layer{layer}_head{head}.json\", \"w\") as fp:\n",
    "            json.dump(point_position_dict[layer][head] , fp)             \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cam_env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
